# -*- coding: utf-8 -*-
"""Proyek Kedua Sistem Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15kzm1FlprXWodJIWbQ6SnG5YcV47lx91

## DATA DIRI
2. Nama = DAFFA RAYHAN RIADI
3. Username = daffarayhanriadi
4. Email = daffarayhanriadi@gmail.com 
5. No. Telepon = +6285277116302
6. Kota Domisili = Purwokerto
7. Tempat Lahir = Kota Padangsidempuan - Sumatera Utara
8. Tanggal Lahir = 03 Oktober 2022
9. Jenis Kelamin = Laki-laki
10. Pendidikan Terakhir = SMA
11. Pekerjaan/Profesi saat ini = Pelajar/Mahasiswa
12. Perusahaan/Institusi saat ini = Institut Teknologi Telkom Purwokerto

## *Import Library*
Melakukan import beberapa library yang diperlukan
"""

import pandas as pd # Untuk membaca file csv dari dataset
import numpy as np # Untuk mengubah data menjadi bentuk array
import matplotlib.pyplot as plt # Untuk visualisasi data
import tensorflow as tf
import keras

from tensorflow.keras import layers 
from sklearn.model_selection import train_test_split # Untuk membagi data latih dan data test
from sklearn.preprocessing import MinMaxScaler # Untuk melakukan normalisasi data

"""## *Data Loading*
Melakukan Data *Loading* dengan [*Dataset*](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset) berikut ini.
"""

data_buku = pd.read_csv('https://raw.githubusercontent.com/Daffarr/Book-Recomendation/main/Dataset/Books.csv')
data_rating = pd.read_csv('https://raw.githubusercontent.com/Daffarr/Book-Recomendation/main/Dataset/Ratings.csv')

data_buku.head(3)

data_rating.head(3)

"""## Data *Understanding*

Variabel-variabel pada *dataset* adalah sebagai berikut: 

*Books.csv*
* ***ISBN***: `Kode pengidentifikasian buku yang bersifat unik.`
* ***Book-Title***: `Judul Buku.`
* ***Book-Author***: `Nama pengarang buku.`
* ***Year-Of-Publication***: `Tahun penerbitan buku.`
* ***Publisher***: `Pihak penerbit buku.`
* ***Image-URL-S***: `URL yang menautkan ke gambar sampul berukuran kecil.`
* ***Image-URL-M***: `URL yang menautkan ke gambar sampul berukuran normal.`
* ***Image-URL-L***: `URL yang menautkan ke gambar sampul berukuran besar.`

*Rating.csv*
* ***User-ID***: `Nomer unik user yang memberikan rating.`
* ***ISBN***: `Kode pengidentifikasian buku yang bersifat unik.`
* ***Book-Rating***: `Skor dari rating yang diberikan.`

### Menghitung Shape Buku dan *Rating*
"""

print("Shape dari data buku:" , data_buku.shape)
print("Shape dari data rating:" , data_rating.shape)

"""### Menghitung Jumlah Total Buku, User dan *Rating*"""

print('Total Jumlah data buku: ', len(data_buku['ISBN'].unique()))
print('Total Jumlah data user yang memberikan rating: ', len(data_rating['User-ID'].unique()))
print('Total Jumlah data rating pada buku: ', len(data_rating['ISBN'].unique()))

"""### Memeriksan Informasi Pada Data"""

data_buku.info()

"""Terlihat dari data buku di atas. Semua kolom data memiliki *type* data *object*, namun disini dapat kita lihat juga bahwa ***Year-Of-Publication*** seharusnya bertipe data *number*, namun karena kita disini tidak menggunakan fitur tersebut pada proyek kali ini, sehingga tidak apa-apa"""

daftar_judul_buku = data_buku['Book-Title'].value_counts().keys()
total_jumlah = data_buku['Book-Title'].value_counts()

jumlah_buku = pd.DataFrame({'Judul-Buku': daftar_judul_buku, 'Total-Jumlah-Buku': total_jumlah}).reset_index(drop=True)
jumlah_buku

daftar_penulis = data_buku['Book-Author'].value_counts().keys()
total_jumlah_penulis = data_buku['Book-Author'].value_counts()

jumlah_penulis = pd.DataFrame({'Nama-Penulis-Buku': daftar_penulis, 'Total-Jumlah-Penulis': total_jumlah_penulis}).reset_index(drop=True)
jumlah_penulis

data_rating.info()

"""Untuk data rating sendiri dapat dilihat diatas terdapat 2 tipe pada data yaitu numerik (*int64*) dan *object*."""

daftar_rating = data_rating['Book-Rating'].value_counts().keys()
jumlah = data_rating['Book-Rating'].value_counts()

jumlah_rating = pd.DataFrame({'Ratings': daftar_rating, 'Total-Jumlah-Rating': jumlah}).reset_index(drop=True)
jumlah_rating

"""### Memeriksan *Missing Value*"""

print("Setiap nilai nol di data Books:")
print(data_buku.isnull().sum(), "\n")
print("===" * 10)
print("\nSetiap nilai nol di data Ratings:")
print(data_rating.isnull().sum())

"""Jika dilihat dari data buku dan data *rating* di atas. Terdapat sedikit *missing value* pada data buku, sedangkan pada data *rating* tidak memiliki *missing value* sama sekali.

### Memeriksa Duplikasi Data
"""

print("Data Duplikasi Pada Books: ")
for col in data_buku.columns:
  print(f'{col}: {data_buku[col].duplicated().sum()}')

print("")
print("===" * 10)

print("\nData Duplikasi Pada Ratings: ")
for col in data_rating.columns:
  print(f'{col}: {data_rating[col].duplicated().sum()}')

"""Dapat dilihat pada tampilan *output* yang ada diatas. Tidak terdapat duplikasi pada data *ISBN* tetapi terdapat banyak duplikasi pada data lainnya. Begitupun pada data *rating*, terdapat banyak duplikasi pada data. Tetapi ini hal yang wajar sebab tiap *user* dapat memberikan *rating* pada tiap buku yang berbeda dan buku yang berbeda dapat menerima *rating* dari *user* yang berbeda pula.

# *Collaborative Filtering*

## Data Preparation

### Menghapus Data Yang Tidak Diperlukan

Sistem rekomendasi ini hanya memerlukan data author dan rating sebagai fitur untuk model. Beberapa kolom data seperti 'Year-Of-Publication', 'Publisher', 'Image-URL-M', 'Image-URL-L' tidak akan digunakan untuk sistem rekomendasi ini. Jadi data tersebut bisa dihapus.
"""

data_buku.drop(['Year-Of-Publication', 'Publisher', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)
data_buku

"""### Melakukan Penggabungan Data Buku dan *Rating*"""

data_rating_baru = data_rating.merge(data_buku,on='ISBN')
data_rating_baru = data_rating_baru.groupby('Book-Title').sum()['Book-Rating'].reset_index()
data_rating_baru.rename(columns={'Book-Rating':'Num-Ratings'}, inplace=True)

data_rating_baru

data_buku_baru = pd.DataFrame({'Book-Title': data_buku['Book-Title'].unique()})

# Menggabungkan data buku dan rating
data_buku_baru = pd.merge(data_buku_baru, data_rating_baru, on='Book-Title', how='left')
data_buku_baru = data_buku_baru.merge(data_buku, on='Book-Title').drop_duplicates('ISBN')

data_buku_baru

"""### Menghapus Data Duplikasi"""

data_buku_baru = data_buku_baru.drop_duplicates('Book-Title').reset_index(drop=True)
len(data_buku_baru['ISBN'].unique()), len(data_buku_baru['Book-Title'].unique())

"""### Menangani Missing Value Pada Data """

data_buku_baru.isnull().sum()

data_buku_baru = data_buku_baru.dropna()
data_buku_baru.shape

data_buku_baru.isnull().sum()

"""### Melakukan Penggabungan Data Rating dan Data Buku Yang Baru (Yang telah di kelola)

Data yang digunakan pada teknik ini tidak memerlukan data *Book-Author* dan *Num-Ratings*. Karena pada teknik ini hanya menggunakan *rating* sebagai acuan sistem rekomendasi.
"""

df_ds = data_rating
df_ds = df_ds.merge(data_buku_baru, on='ISBN')
df_ds.drop(['Num-Ratings', 'Book-Author'], axis=1, inplace=True)
df_ds

"""### Menyandikan Fitur
Membuat penyandian untuk fitur User-ID dan Book-Title menjadi dalam bentuk index
"""

user_id_ds = df_ds['User-ID'].unique().tolist()
user2encoded = {x: i for i, x in enumerate(user_id_ds)}
encoded2user = {i: x for i, x in enumerate(user_id_ds)}

book_isbn_ds = df_ds['ISBN'].unique().tolist()
book2encoded = {x: i for i, x in enumerate(book_isbn_ds)}
encoded2book = {i: x for i, x in enumerate(book_isbn_ds)}

df_ds['User-Encoded'] = df_ds['User-ID'].map(user2encoded)
df_ds['Book-Encoded'] = df_ds['ISBN'].map(book2encoded)

num_users = len(user2encoded)
print(num_users)
 
num_books = len(encoded2book)
print(num_books)

df_ds['Book-Rating'] = df_ds['Book-Rating'].values.astype(np.float32)
 
min_rating = min(df_ds['Book-Rating'])
max_rating = max(df_ds['Book-Rating'])

print(f'Number of User: {num_users}, Number of Books: {num_books}, Min Rating: {min_rating}, Max Rating: {max_rating}')

df_ds

"""### Normalisasi Data *Rating*

Melakukan transformasi pada data fitur *Book-Rating* dengan menggunakan library *MinMaxScaler*. *MinMaxScaler* mentransformasikan fitur dengan menskalakan setiap fitur ke rentang tertentu. *Library* ini menskalakan dan mentransformasikan setiap fitur secara individual sehingga berada dalam rentang yang diberikan pada set pelatihan, pada *library* ini memiliki *range default* antara nol dan satu.
"""

x = df_ds[['User-Encoded', 'Book-Encoded']].values
y = df_ds['Book-Rating'].values
y = y.reshape(-1, 1)

scaler = MinMaxScaler()
y = scaler.fit_transform(y)
y = y.reshape(1, -1)[0]

"""### *Split Dataset*
Membagi *dataset* menjadi data latih **(x_*train* & y_*train*)** dan data uji **(x_*test* & y_*test*)** sebelum membuat model. Data latih adalah sekumpulan data yang akan digunakan oleh model *machine learning* untuk melakukan pelatihan. Sedangkan data uji adalah sekumpulan data yang akan digunakan untuk memvalidasi kinerja pada model *machine learning* yang telah dilatih. Karena data uji berperan sebagai data baru yang belum pernah dilihat oleh model *machine learning*, maka cara ini efektif untuk memeriksa performa model *machine learning* setelah proses pelatihan dilakukan. Proporsi pembagian *dataset* pada proyek ini menggunakan proporsi pembagian **90:10** yang berarti sebanyak **90% merupakan data latih** dan **10% persen merupakan data uji**, kemudian ***random_state** bernilai **32**.
"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=32)

def create_dataset(x, y, batch_size, buffer_size=None, shuffle=True):
  ds = tf.data.Dataset.from_tensor_slices((x, y))
  if shuffle:
    ds = ds.shuffle(buffer_size)
  ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)
  return ds

batch_size = 128
buffer_size = len(x)

train_ds = create_dataset(x_train, y_train, batch_size, buffer_size)
val_ds = create_dataset(x_test, y_test, batch_size, shuffle=False)

"""## *Modelling*

### Membuat Model
Membuat Model *machine learning* Untuk Rekomendasi, Langkah yang pertama yaitu dengan menggabungkan data buku dan rating. Setelah itu melakukan penyandian terhadap data User-ID dan ISBN dan memisahkan data latih dan data validasi dengan ratio 90:10. Kemudian membuat model untuk melakukan pelatihan pada data. Model ini menggunakan operasi perkalian dot product antara embedding user dan book. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid. Untuk mendapatkan hasil rekomendasi, dipilih User-ID secara acak dan akan dilakukan penyaringan daftar buku yang belum pernah dibaca oleh user. Pastinya teknik ini memiliki kelebihan dan kekurangannya sendiri, yaitu sebagai berikut:
"""

class RecommenderNet(tf.keras.Model):
  def __init__(self, num_users, num_books, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)

    self.num_users = num_users
    self.num_books = num_books
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer='he_normal',
        embeddings_regularizer=keras.regularizers.l2(1e-3),
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.books_embedding = layers.Embedding(
        num_books,
        embedding_size,
        embeddings_initializer='he_normal',
        embeddings_regularizer=keras.regularizers.l2(1e-3),
    )
    self.books_bias = layers.Embedding(num_books, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:, 0])
    user_bias = self.user_bias(inputs[:, 0])
    books_vector = self.books_embedding(inputs[:, 1])
    books_bias = self.books_bias(inputs[:, 1])

    dot_user_books = tf.tensordot(user_vector, books_vector, 2)

    x = dot_user_books + user_bias + books_bias

    return tf.nn.sigmoid(x)

embedding_size = 32

model = RecommenderNet(num_users, num_books, embedding_size)
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""### Melatih Model
Melahtih model rekomendasi yang telah dibuat dengan epoch sebanyak 40
"""

history = model.fit(
  train_ds,
  epochs = 40,
  validation_data = val_ds,
  verbose=1,
)

"""### Mendapatkan Rekomendasi Buku
Melihat hasil rekomendasi dari model yang telah dilatih
"""

books_df = data_buku_baru.drop(['Num-Ratings', 'Book-Author'], axis=1)
df = pd.read_csv('https://raw.githubusercontent.com/Daffarr/Book-Recomendation/main/Dataset/Ratings.csv')
 
user_id = df['User-ID'].sample(1).iloc[0]
book_choosen_by_user = df[df['User-ID'] == user_id]

book_no_choosen = books_df[~books_df['ISBN'].isin(book_choosen_by_user['ISBN'].values)]['ISBN']
book_no_choosen = list(
    set(book_no_choosen).intersection(set(book2encoded.keys())))
 
book_no_choosen = [[book2encoded.get(x)] for x in book_no_choosen]
user_encoder = user2encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_no_choosen), book_no_choosen))

ratings = model.predict(user_book_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_books_ids = [
    encoded2book.get(book_no_choosen[x][0]) for x in top_ratings_indices
]
 
print(f'Menampilkan rekomendasi untuk pengguna: {user_id}')
print('===' * 11)
print('Buku dengan peringkat tinggi dari pengguna')
print('----' * 8)
 
top_book_user = (
    book_choosen_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)['ISBN'].values
)
 
books_df_rows = books_df[books_df['ISBN'].isin(top_book_user)]
for row in books_df_rows.itertuples():
    print(f'{row[1]} ({row[3]})')
 
print('----' * 8)
print('Rekomendasi 10 buku terbaik')
print('----' * 8)
 
recommended_book = books_df[books_df['ISBN'].isin(recommended_books_ids)]
for row in recommended_book.itertuples():
    print(f'{row[1]} ({row[3]})')

"""### Visualisasi Metrik *RMSE*
Menampilkan visualisasi metrik *RMSE* dengan menggunakan *library* matplotlib
"""

fig = plt.gcf()
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.grid()
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['root_mean_squared_error', 'val_root_mean_squared_error'])
plt.show()

"""Dari hasil pelatihan yang dilakukan. Dapat dilihat bahwa nilai metrik *RMSE* berada di sekitar 0.38 untuk *training* dan disekitar 0.36 untuk validasi."""